{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio con kNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, descargamos un dataset sobre el que vamos a trabajar en nuestro ejercicio en un subdirectorio `data` de nuestro directorio de trabajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 23873  100 23873    0     0  26853      0 --:--:-- --:--:-- --:--:-- 26823\n"
     ]
    }
   ],
   "source": [
    "!curl -o data/diabetes.csv https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargamos los módulos que utilizaremos en el ejercicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestros sospechosos habituales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# También, como siempre, nos apoyamos en Scikit-Learn para hacer el split en training y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Usaremos el preprocesador StandardScaler para no tener sesgos en los datos\n",
    "# de entrada\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Importamos herramientas para evaluar el modelo. F1 es la media\n",
    "# armónica de precision y recall\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el turno de cargar el dataset en un Pandas dataframe y de investigar un poco qué es lo que tenemos en términos de número de muestras y de features. Apoyaos en la documentación pública de Pandas para investigar cómo cargar un dataset (lo veremos en clase de todas formas). Escribid el código en los placeholders marcados con `#tu código aquí#`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el CSV que hemos descargado con la ayuda de los métos que nos ofrecen\n",
    "# los dataframes de Pandas\n",
    "dataset = #tu código aquí#\n",
    "\n",
    "# Vemos cuántas muestras tiene nuestro dataset\n",
    "#tu código aquí#\n",
    "\n",
    "# Miramos también qué pinta tiene el dataset desde el\n",
    "# punto de vista de características y etiquetas, usando las capacidades de\n",
    "# nuevo de los dataframes de Pandas\n",
    "#tu código aquí#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata de investigar si hay columnas del dataset que contienen valores que son nulos y que no tienen sentido. Como ejemplo, un grosor de piel de valor cero no tiene mucho sentido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe código para filtrar los valores nulos de 1 columna del DataFrame y visualizarlos,\n",
    "# deberías poder hacerlo en 1 línea\n",
    "#tu código aquí#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para la columna correspondiente a la feature que has elegido explorar (por ejemplo, skinThickness), calcula la media de los valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la media de los valores de 1 columna de tu DataFrame\n",
    "#tu código aquí#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que vamos a hacer ahora es sustituir los valores nulos por la media de todos los valores de la columna, con el objetivo de poder seguir contando con las muestras que los tienen. Como pista, debes hacer esa operación para todas estas columnas en el DataFrame: 'Glucose','BloodPressure','SkinThickness','BMI','Insulin'. Lo mejor es que escribas código que itere sobre esas columnas para realizar la operación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacena las columnas a alterar en una lista de Python\n",
    "#tu código aquí#\n",
    "\n",
    "# Itera sobre cada elemento de la lista, calculando la media y posteriormente sustituyendo los ceros por el valor calculado de la media\n",
    "#tu código aquí#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el proceso de entrenamiento, como siempre, partimos el dataset en training y test. Elige un 20% del dataset para el conjunto de testing, dejando el 80% restante para el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerda que la columna nueve (índice 8) es la que tiene\n",
    "# nuestras etiquetas, y que el resto contiene las features.\n",
    "X = #tu código aquí#\n",
    "y = #tu código aquí#\n",
    "# Haz el split, selecciona un 20% del dataset original como datos de test\n",
    "X_train, X_test, y_train, y_test = #tu código aquí#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente será escalar los datos, ésta es una técnica de ingeniería de características que será necesaria para poder calcular distancias correctamente con KNNs (veremos más sobre esto en clase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora escalamos los datos, de manera que todos los rangos van desde -1 hasta 1.\n",
    "sc_X = StandardScaler()\n",
    "# Hacemos training y transformación conjunta sobre el training set\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "# Tenemos que asegurarnos de que el testing set también está transformado\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una buena estimación del número de vecinos suele ser la raíz cuadrada del número de características. Usa este número como tu configuración inicial de `n_neighbors` y procede crear y entrenar un kNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el modelo, inicializando kNN con los datos seleccionados\n",
    "cls = #tu código aquí#\n",
    "# Entrena el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, evalua el modelo sobre el dataset de test, y muestra la precisión obtenida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tu código aquí#"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "ks-sl",
   "language": "python",
   "name": "ks-sl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
